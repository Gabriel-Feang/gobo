# Gobo ðŸ’

*"Gobo, isolate the behaviors you want. Stop stubbing when you can simulate intelligent behavior."*

Gobo is a lightweight Go middleware designed to intercept HTTP requests during integration tests and substitute them with intelligent, context-aware mock responses generated by an LLM.

Instead of meticulously hard-coding JSON stubs for every edge case in your tests, you simply define the **expected struct schema** and add hints for the LLM using the custom `gobo` struct tag. Gobo intercepts the network call, sends the request's context and schema to the LLM, and seamlessly unmarshals the realistic AI-generated JSON back to your application.

## For AI Integration Agents (MCP)
If you are an AI test-runner agent using MCP, Gobo is **designed specifically for you**. 

Instead of writing verbose test files and mocking functions, you can start the target application, spin up Gobo with the `AsyncBroker`, and intercept all outbound HTTP requests indefinitely. Gobo will "pause" the HTTP call until youâ€”the Agentâ€”use the `broker.GetPendingRequests()` and `broker.SubmitResponse()` API to manually fulfill the request using your own context!

---

## Installation

```bash
go get github.com/feang/gobo
```

## Quick Start (Ollama LLM)

By default, Gobo comes with an `OllamaGenerator` that connects to a local Ollama instance (e.g., running `llama3` or `mistral`).

```go
package main

import (
	"log"
	"net/http"
	"net/http/httptest"
	"github.com/feang/gobo"
)

// 1. Define the schema of the downstream API you want to mock
type PaymentResponse struct {
	TransactionID string `json:"transaction_id" gobo:"A valid UUID v4"`
	Status        string `json:"status" gobo:"Must always be 'APPROVED'"`
}

func main() {
	// 2. Initialize Gobo
	mock := gobo.New(gobo.Config{
		OllamaURL: "http://localhost:11434",
		Model:     "llama3",
		Debug:     true,
	})

	// 3. Register the endpoint and the expected struct schema
	mock.Register("POST", "/v1/charge", PaymentResponse{})

	// 4. Wrap your standard mux or test server with the Gobo middleware
	// Any non-registered route will pass through normally!
	ts := httptest.NewServer(mock.Middleware(http.NewServeMux()))
	defer ts.Close()

	// 5. Point your application to the `ts.URL` instead of the real downstream service.
	log.Printf("Gobo is intercepting requests at: %s", ts.URL)
}
```

## Dynamic Prompt Engineering (`gobo` Tags)

Gobo dynamically parses your structs using Go reflection. It looks for the `gobo` struct tag to provide explicit, field-level instructions to the LLM. 

```go
type User struct {
    ID    string `json:"id" gobo:"A UUID"`
    Name  string `json:"name" gobo:"A creative internet handle"`
    Email string `json:"email" gobo:"A valid email for a tech company"`
}
```
You don't need to do anything else. Gobo will extract these tags and enforce them in the LLM's system prompt.

---

## Advanced: The `AsyncBroker` (For Testing Agents)

If testing via an AI agent, or if you need to manually inspect and orchestrate mocked responses without LLM timeouts, use the `AsyncBroker`. 

The `AsyncBroker` implements Gobo's `Generator` interface by parking the intercepted HTTP request indefinitely, waiting for an external system to submit the response.

```go
// Setup
broker := gobo.NewAsyncBroker()

mock := gobo.New(gobo.Config{
    Generator: broker,
})

mock.Register("GET", "/users", UserSchema{})
ts := httptest.NewServer(mock.Middleware(http.NewServeMux()))

// ... Meanwhile, in another Go routine or via an Agent MCP Tool:
pending := broker.GetPendingRequests()

if len(pending) > 0 {
    // Inspect what the application asked for
    fmt.Println(pending[0].Context.URL)

    // Fulfill the blocked HTTP request asynchronously!
    broker.SubmitResponse(pending[0].ID, []byte(`{"id": "mocked-by-agent"}`))
}
```

## Custom LLMs (`Generator` Interface)
If you don't want to use Ollama or the AsyncBroker, you can wire up OpenAI, Anthropic, or any other LLM by implementing the `Generator` interface and passing it in `gobo.Config`.

```go
type Generator interface {
	GenerateResponse(ctx context.Context, reqCtx RequestContext, schema any) ([]byte, error)
}
```
